Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Jebari2013,
abstract = {In this paper, an experimental study of six well known selection methods has conducted to a new technique of selection. Dynamic selection (DS), the proposed technique, exploits the advantages of each selection methods in terms of quality of solution and population diversity. Indeed, dynamic selection is based on two parameters that allow to decide the quality of candidate solutions and the genotypic diversity. The famous 0-1 Knapsack Problem is used to illustrate the efficiency of DS.},
author = {Jebari, Khalid and Mediafi, Mohammed and Elmoujahid, Abdelaziz},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/V2I11-IJERTV2IS110523.pdf:pdf},
journal = {International Journal of Engineering Research {\&} Technology (IJERT)},
number = {11},
pages = {1141--1145},
title = {{Parent Selection Operators for Genetic Algorithms}},
volume = {2},
year = {2013}
}
@incollection{Jyotishree2012a,
abstract = {A genetic algorithm operates on population of constant size. An initial population of individuals is generated randomly or heuristically. Selection operator is used to improve the quality of the population by selecting the fittest individuals to form the mating pool. Crossover operator takes two individuals with higher fitness values from the mating pool and randomly chooses the position and length of the portion to be exchanged and performs this operation at either single or multiple points. Mutation introduces new genetic structures in the population by randomly modifying some of the genes, helping the search algorithm to escape from local optimum by reaching new points in the search space. Current generation of individuals is replaced by newly generated offsprings by the specific replacement strategy. Genetic algorithms are stochastic iterative algorithms, so the algorithm iterates till maximum number of generations is reached or the cycle of genetic algorithm continues until the optimal solution is achieved. When a new generation of offsprings is produced, the next question is which of these newly generated offsprings would move forward to the next generation and would replace which chromosomes of the current generation. The answer to this question is based on Darwin's principle of "Survival of Fittest". So better fit individuals have more chances to survive and carried forward to next generation leaving behind the less fit ones. The process of forming next generation of individuals by replacing or removing some offsprings or parent individuals is done by replacement operator. This process in evolution is known as replacement scheme. Replacement strategy helps to find out the individuals that would replace the current generation to form next generation of population.},
author = {Jyotishree, Jyotishree and Kumar, Rakesh},
booktitle = {Knowledge based operation and problems representation in genetic algorithms},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Chapter 7 REPLACEMENT 7.1 Need of Replacement.pdf:pdf},
organization = {Kurukshetra University},
pages = {125--135},
title = {{Chapter 7 : REPLACEMENT}},
year = {2012}
}
@article{Gebser2007,
abstract = {We describe the conflict-driven answer set solver clasp, which is based on concepts from constraint processing (CSP) and satisfiability checking (SAT). We detail its system architecture and major features, and provide a systematic empirical evaluation of its features. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Gebser, Martin and Kaufmann, Benjamin and Neumann, Andr{\'{e}} and Schaub, Torsten},
doi = {10.1007/978-3-540-72200-7_23},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/GebserKNS07a.pdf:pdf},
isbn = {9783540721994},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {260--265},
title = {{clasp: A conflict-driven answer set solver}},
volume = {4483 LNAI},
year = {2007}
}
@article{Gent2006,
abstract = {Efficient constraint propagation is crucial to any constraint solver. We show that watched literals, already a great success in the satisfiability community, can be used to provide highly efficient implementations of constraint propagators. We describe three important aspects of watched literals as we apply them to constraints, and how they are implemented in the MINION constraint solver. We show three successful applications of to constraint propagators: the sum of Boolean variables; GAG for the 'element' constraint; and GAG for the 'table' constraint. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
author = {Gent, Ian P. and Jefferson, Chris and Miguel, Ian},
doi = {10.1007/11889205_15},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/GentJeffersonMiguelCP06.pdf:pdf},
isbn = {3540462678},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {182--197},
title = {{Watched literals for constraint propagation in Minion}},
volume = {4204 LNCS},
year = {2006}
}
@article{Jarvisalo2012,
abstract = {Decision procedures for Boolean satisfiability (SAT), especially modern conflict-driven clause learning (CDCL) solvers, act routinely as core solving engines in various real-world applications. Preprocessing, i.e., applying formula rewriting/simplification rules to the input formula before the actual search for satisfiability, has become an essential part of the SAT solving tool chain. Further, some of the strongest SAT solvers today add more reasoning to search by interleaving formula simplification and CDCL search. Such inprocessing SAT solvers witness the fact that implementing additional deduction rules in CDCL solvers leverages the efficiency of state-of-the-art SAT solving further. In this paper we establish formal underpinnings of inprocessing SAT solving via an abstract inprocessing framework that covers a wide range of modern SAT solving techniques. {\textcopyright} 2012 Springer-Verlag.},
author = {J{\"{a}}rvisalo, Matti and Heule, Marijn J.H. and Biere, Armin},
doi = {10.1007/978-3-642-31365-3_28},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/jarvisalo-heule-biere.ijcar12.pdf:pdf},
isbn = {9783642313646},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {355--370},
title = {{Inprocessing rules}},
volume = {7364 LNAI},
year = {2012}
}
@techreport{Gottlieb,
abstract = {Several evolutionary algorithms have been proposed for the satisfiability problem. We review the solution representations suggested in literature and choose the most promising one - the bit string representation - for further evaluation. An empirical comparison on commonly used benchmarks is presented for the most successful evolutionary algorithms and for WSAT, a prominent local search algorithm for the satisfiability problem. The key features of successful evolutionary algorithms are identified, thereby providing useful methodological guidelines for designing new heuristics. Our results indicate that evolutionary algorithms are competitive to WSAT.},
author = {Gottlieb, Jens and Marchiori, Elena and Rossi, Claudio},
booktitle = {Evolutionary Computation},
doi = {10.1162/106365602317301763},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gottlieb, Marchiori, Rossi - Unknown - Evolutionary Algorithms for the Satisfiability Problem.pdf:pdf},
issn = {10636560},
keywords = {Adaptive fitness function,Evolutionary algorithm,Local search,Satisfiability problem,WSAT},
number = {1},
pages = {35--50},
title = {{Evolutionary algorithms for the satisfiability problem}},
volume = {10},
year = {2002}
}
@misc{Cook1971,
abstract = {It is shown that any recognition problem solved by a polynomial timebounded nondeterministic Turing machine can be "reduced" to the problem of determining whether a given propositional formula is a tautology. Here "reduced" means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed. Throughout this paper, a set of strings means a set of strings on some fixed, large, finite alphabet Z. This alphabet is large enough to include symbols for all sets described here. All Turing machines are deterministic recognition devices, unless the contrary is explicitly stated.},
author = {Cook, Stephen A.},
booktitle = {Proceedings of the Annual ACM Symposium on Theory of Computing},
doi = {10.1145/800157.805047},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/1971.pdf:pdf},
issn = {07378017},
pages = {151--158},
title = {{The complexity of theorem-proving procedures}},
year = {1971}
}
@inproceedings{Moskewicz2001,
abstract = {Boolean satisfiability is probably the most studied of the combinatorial optimization/search problems. Significant effort has been devoted to trying to provide practical solutions to this problem for problem instances encountered in a range of applications in electronic design automation (EDA), as well as in artificial intelligence (AI). This study has culminated in the development of several SAT packages, both proprietary and in the public domain (e.g. GRASP, SATO) which find significant use in both research and industry. Most existing complete solvers are variants of the Davis-Putnam (DP) search algorithm. In this paper we describe the development of a new complete solver, Chaff which achieves significant performance gains through careful engineering of all aspects of the search-especially a particularly efficient implementation of Boolean constraint propagation (BCP) and a novel low overhead decision strategy. Chaff has been able to obtain one to two orders of magnitude performance improvement on difficult SAT benchmarks in comparison with other solvers (DP or otherwise), including GRASP and SATO.},
author = {Moskewicz, M.W. and Madigan, C.F. and Zhao, Y. and Zhang, L. and Malik, S.},
booktitle = {Proceedings of the 38th Design Automation Conference (IEEE Cat. No.01CH37232)},
doi = {10.1145/378239.379017},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/DAC2001v56.pdf:pdf},
keywords = {Artificial intelligence,Boolean constraint propagation,Boolean functions,Boolean satisfiability,Business continuity,Chaff,Design automation,Design engineering,Electronic design automation and methodology,Electronics packaging,Logic testing,NP-complete problem,Performance gain,Permission,SAT benchmarks,SAT solver,artificial intelligence,computational complexity,constraint theory,electronic design automation,formal verification,low overhead decision strategy},
pages = {530--535},
title = {{Chaff: engineering an efficient SAT solver}},
url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp={\&}arnumber=935565{\&}isnumber=20239},
year = {2001}
}
@techreport{Biere2010,
author = {Biere, Armin},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/Biere-FMV-TR-10-1.pdf:pdf},
institution = {Institute for Formal Models and Verification, Johannes Kepler University, Linz, Austria},
number = {August},
pages = {4},
title = {{Lingeling, Plingeling, PicoSAT and PrecoSAT at SAT Race 2010}},
url = {http://baldur.iti.uka.de/sat-race-2010/},
year = {2010}
}
@article{Cochran2011,
abstract = {Random search algorithms are useful for many ill-structured global optimization problems with continuous and/or discrete variables. Typically random search algo- rithms sacrifice a guarantee of optimality for finding a good solution quickly with convergence results in probability. Random search algorithms include simulated an- nealing, tabu search, genetic algorithms, evolutionary programming, particle swarm optimization, ant colony optimization, cross-entropy, stochastic approximation, multi- start and clustering algorithms, to name a few. They may be categorized as global (exploration) versus local (exploitation) search, or instance-based versus model-based. However, one feature these methods share is the use of probability in determining their iterative procedures. This article provides an overview of these random search algorithms, with a probabilistic view that ties them together.},
author = {Cochran, James J. and Cox, Louis A. and Keskinocak, Pinar and Kharoufeh, Jeffrey P. and Smith, J. Cole and Zabinsky, Zelda B.},
doi = {10.1002/9780470400531.eorms0704},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/AdapRandomSearch4.05.2009.pdf:pdf},
journal = {Wiley Encyclopedia of Operations Research and Management Science},
title = {{Random Search Algorithms}},
year = {2011}
}
@article{Davis1962,
abstract = {The programming of a proof procedure is discussed in connection with trial runs and possible improvements. {\textcopyright} 1962, ACM. All rights reserved.},
author = {Davis, Martin and Logemann, George and Loveland, Donald},
doi = {10.1145/368273.368557},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/Dav62.pdf:pdf},
issn = {15577317},
journal = {Communications of the ACM},
number = {7},
pages = {394--397},
title = {{A machine program for theorem-proving}},
volume = {5},
year = {1962}
}
@article{Maaranen2004,
abstract = {The selection of the initial population in a population-based heuristic optimizationmethod is important, since it affects the search for several iterations and often has an influence on the final solution. If no a priori information about the optima is available, the initial population is often selected randomly using pseudorandom numbers. Usually, however, it is more important that the points are as evenly distributed as possible than that they imitate random points. In this paper, we study the use of quasi-random sequences in the initial population of a genetic algorithm. Sample points in a quasi-random sequence are designed to have good distribution properties. Here a modified genetic algorithm using quasi-random sequences in the initial population is tested by solving a large number of continuous benchmark problems from the literature. The numerical results of two implementations of genetic algorithms using different quasi-random sequences are compared to those of a traditional implementation using pseudorandom numbers. The results obtained are promising.},
author = {Maaranen, H. and Miettinen, K. and M{\"{a}}kel{\"{a}}, M.M.},
doi = {10.1016/j.camwa.2003.07.011},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maaranen, Miettinen, M{\"{a}}kel{\"{a}} - 2004 - Quasi-random initial population for genetic algorithms.pdf:pdf},
issn = {08981221},
journal = {Computers {\&} Mathematics with Applications},
month = {jun},
number = {12},
pages = {1885--1895},
publisher = {Elsevier BV},
title = {{Quasi-random initial population for genetic algorithms}},
volume = {47},
year = {2004}
}
@article{Savitch1970,
abstract = {The amount of storage needed to simulate a nondeterministic tape bounded Turingmachine on a deterministic Turing machine is investigated. Results include the following: Theorem. A nondeterministic L(n)-tape bounded Turing machine can be simulated by a deterministic [L(n)]2-tape bounded Turing machine, provided L(n)â‰¥log2n. Computations of nondeterministic machines are shown to correspond to threadings of certain mazes. This correspondence is used to produce a specific set, namely the set of all codings of threadable mazes, such that, if there is any set which distinguishes nondeterministic tape complexity classes from deterministic tape complexity classes, then this is one such set. {\textcopyright} 1970 Academic Press, Inc.},
author = {Savitch, Walter J.},
doi = {10.1016/S0022-0000(70)80006-X},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/82306488.pdf:pdf},
issn = {10902724},
journal = {Journal of Computer and System Sciences},
number = {2},
pages = {177--192},
title = {{Relationships between nondeterministic and deterministic tape complexities}},
volume = {4},
year = {1970}
}
@article{Hamadi2009,
abstract = {Multiple sclerosis (MS) is a progressive neurological disorder that disrupts axonal myelin in the central nervous system. Demyelination produces alterations in saltatory conduction, slowed conduction velocity, and a predisposition to conduction block. An estimated 60-80{\%} of MS patients experience temporary worsening of clinical signs and neurological symptoms with heat exposure. Additionally, MS may produce impaired neural control of autonomic and endocrine functions. This review focuses on five main themes regarding the current understanding of thermoregulatory dysfunction in MS: 1) heat sensitivity; 2) central regulation of body temperature; 3) thermoregulatory effector responses; 4) heat-induced fatigue; and 5) countermeasures to improve or maintain function during thermal stress. Heat sensitivity in MS is related to the detrimental effects of increased temperature on action potential propagation in demyelinated axons, resulting in conduction slowing and/or block, which can be quantitatively characterized using precise measurements of ocular movements. MS lesions can also occur in areas of the brain responsible for the control and regulation of body temperature and thermoregulatory effector responses, resulting in impaired neural control of sudomotor pathways or neural-induced changes in eccrine sweat glands, as evidenced by observations of reduced sweating responses in MS patients. Fatigue during thermal stress is common in MS and results in decreased motor function and increased symptomatology likely due to impairments in central conduction. Although not comprehensive, some evidence exists concerning treatments (cooling, precooling, and pharmacological) for the MS patient to preserve function and decrease symptom worsening during heat stress.},
author = {Hamadi, Youssef and Jabbour, Said and Sais, Lakhdar},
doi = {10.3233/sat190070},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/jsatmanysat.pdf:pdf},
issn = {1574-0617},
journal = {Journal on Satisfiability, Boolean Modeling and Computation},
keywords = {dynamic restarts,extended clause learning,parallel search,published june 2009,revised may 2009,submitted november 2008},
number = {4},
pages = {245--262},
title = {{ManySAT: a Parallel SAT Solver}},
volume = {6},
year = {2009}
}
@article{Bhattacharjee2017,
abstract = {In this paper we propose our genetic algorithm for solving the SAT problem. We introduce various crossover and mutation techniques and then make a comparative analysis between them in order to find out which techniques are the best suited for solving a SAT instance. Before the genetic algorithm is applied to an instance it is better to seek for unit and pure literals in the given formula and then try to eradicate them. This can considerably reduce the search space, and to demonstrate this we tested our algorithm on some random SAT instances. However, to analyse the various crossover and mutation techniques and also to evaluate the optimality of our algorithm we performed extensive experiments on benchmark instances of the SAT problem. We also estimated the ideal crossover length that would maximise the chances to solve a given SAT instance.},
author = {Bhattacharjee, Arunava and Chauhan, Prabal},
doi = {10.25046/aj020416},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharjee, Chauhan - 2017 - Solving the SAT problem using genetic algorithm.pdf:pdf},
issn = {24156698},
journal = {Advances in Science, Technology and Engineering Systems},
keywords = {CNF,Crossover,Elitism,Genetic Algorithm,Mutation,SAT},
number = {4},
pages = {115--120},
publisher = {ASTES Publishers},
title = {{Solving the SAT problem using genetic algorithm}},
volume = {2},
year = {2017}
}
@article{Hassanat2019,
abstract = {Genetic algorithm (GA) is an artificial intelligence search method that uses the process of evolution and natural selection theory and is under the umbrella of evolutionary computing algorithm. It is an efficient tool for solving optimization problems. Integration among (GA) parameters is vital for successful (GA) search. Such parameters include mutation and crossover rates in addition to population that are important issues in (GA). However, each operator of GA has a special and different influence. The impact of these factors is influenced by their probabilities; it is difficult to predefine specific ratios for each parameter, particularly, mutation and crossover operators. This paper reviews various methods for choosing mutation and crossover ratios in GAs. Next, we define new deterministic control approaches for crossover and mutation rates, namely Dynamic Decreasing of high mutation ratio/dynamic increasing of low crossover ratio (DHM/ILC), and Dynamic Increasing of Low Mutation/Dynamic Decreasing of High Crossover (ILM/DHC). The dynamic nature of the proposed methods allows the ratios of both crossover and mutation operators to be changed linearly during the search progress, where (DHM/ILC) starts with 100{\%} ratio for mutations, and 0{\%} for crossovers. Both mutation and crossover ratios start to decrease and increase, respectively. By the end of the search process, the ratios will be 0{\%} for mutations and 100{\%} for crossovers. (ILM/DHC) worked the same but the other way around. The proposed approach was compared with two parameters tuning methods (predefined), namely fifty-fifty crossover/mutation ratios, and the most common approach that uses static ratios such as (0.03) mutation rates and (0.9) crossover rates. The experiments were conducted on ten Traveling Salesman Problems (TSP). The experiments showed the effectiveness of the proposed (DHM/ILC) when dealing with small population size, while the proposed (ILM/DHC) was found to be more effective when using large population size. In fact, both proposed dynamic methods outperformed the predefined methods compared in most cases tested.},
author = {Hassanat, Ahmad and Almohammadi, Khalid and Alkafaween, Esra'a and Abunawas, Eman and Hammouri, Awni and Prasath, V. B.Surya},
doi = {10.3390/info10120390},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/information-10-00390.pdf:pdf},
issn = {20782489},
journal = {Information (Switzerland)},
keywords = {Crossover,Genetic algorithms,Mutation,Parameter selection,Ratios},
number = {12},
title = {{Choosing mutation and crossover ratios for genetic algorithms-a review with a new dynamic approach}},
volume = {10},
year = {2019}
}
@article{Saini2017,
abstract = {Genetic Algorithm solves a problem using an evolutionary approach by generating mutations to the current solution method, selecting the better methods from this new generation, and then using these improved methods to repeat the process. Selection is the process of finding out the best individuals for mating process so that the offsprings are produced are fit than the previous population. This paper reviews the commonly used selection methods.},
author = {Saini, Nisha},
doi = {10.18535/ijecs/v6i12.04},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saini - 2017 - Review of Selection Methods in Genetic Algorithms.pdf:pdf},
isbn = {2326123263},
journal = {International Journal Of Engineering And Computer Science},
keywords = {Boltzmann selection,Genetic Algorithm,Rank selection,Roulette wheel,Tournament selection},
pages = {23261--23263},
title = {{Review of Selection Methods in Genetic Algorithms}},
url = {www.ijecs.in},
volume = {6},
year = {2017}
}
@techreport{Biere2012,
author = {Biere, Armin},
booktitle = {Proceedings of SAT Challenge 2012; Solver and Benchmark Descriptions},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/Biere-SAT-Challenge-2012.pdf:pdf},
isbn = {9789515100436},
pages = {2},
title = {{Lingeling and friends entering the SAT challenge 2012}},
year = {2012}
}
@techreport{Harmeling2000,
abstract = {We show how to solve hard 3-SAT problems using genetic algorithms. Furthermore, we explore other genetic operators that may be useful to tackle 3-SAT problems, and discuss their pros and cons.},
author = {Harmeling, Stefan},
booktitle = {Genetic Algorithms and Genetic Programming at Stanford 2000},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harmeling - 2000 - Solving Satisfiability Problems with Genetic Algorithms.pdf:pdf},
isbn = {9781424438679},
keywords = {genetic algorithms},
pages = {206--213},
title = {{Solving Satisfiability Problems with Genetic Algorithms}},
year = {2000}
}
@article{Burke2004,
abstract = {This paper examines measures of diversity in genetic programming. The goal is to understand the importance of such measures and their relationship with fitness. Diversity methods and measures from the literature are surveyed and a selected set of measures are applied to common standard problem instances in an experimental study. Results show the varying definitions and behaviors of diversity and the varying correlation between diversity and fitness during different stages of the evolutionary process. Populations in the genetic programming algorithm are shown to become structurally similar while maintaining a high amount of behavioral differences. Conclusions describe what measures are likely to be important for understanding and improving the search process and why diversity might have different meaning for different problem domains.},
author = {Burke, Edmund K. and Gustafson, Steven and Kendall, Graham},
doi = {10.1109/TEVC.2003.819263},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burke, Gustafson, Kendall - 2004 - Diversity in Genetic Programming An Analysis of Measures and Correlation with Fitness.pdf:pdf},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Diversity,Genetic programming,Population dynamics},
month = {feb},
number = {1},
pages = {47--62},
title = {{Diversity in Genetic Programming: An Analysis of Measures and Correlation with Fitness}},
volume = {8},
year = {2004}
}
@inproceedings{Loviskova2015,
abstract = {The goal of the article is to compare efficiency of solving a problem of determining satisfiability of logical formulas SAT (3-SAT), which belongs to a class of NP-complete problems, either by using simple genetic algorithms or using genetic algorithms with suggested modified mechanism of stepwise adaptation of weights (SAW). Two possible ways of dealing with constraint - either based on a penalization or based on a remuneration are compared here. It is shown, on the basis of repeated and evaluated experiments, that a genetic algorithm with suggested mechanism of stepwise adaptation of weights (SAW) is much more efficient for solving the 3-SAT problem.},
author = {Lov{\'{i}}{\v{s}}kova, Jana},
booktitle = {INES 2015 - IEEE 19th International Conference on Intelligent Engineering Systems, Proceedings},
doi = {10.1109/INES.2015.7329708},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lov{\'{i}}{\v{s}}kova - 2015 - Solving the 3-SAT problem using genetic algorithms.pdf:pdf},
isbn = {9781467379397},
keywords = {3-SAT problem,NP-complete problem,backtracking,genetic algorithm (GA),local searching,stepwise adaptation of weights (SAW)},
month = {nov},
pages = {207--212},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Solving the 3-SAT problem using genetic algorithms}},
year = {2015}
}
@article{Aiman2015,
abstract = {SAT-3 is an NP-complete problem for determining whether there exists a solution satisfying a given Boolean formula in the Conjunctive Normal Form, wherein each clause has at most three literals. Existing approaches of this problem take exponential time and are also memory inefficient. The work uses Genetic Algorithms for finding an optimal solution to this problem. The central idea is the intelligent exploitation of a random search used to solve optimization problems. The work explores previous works to direct the search into regions of better performance within the search space, thus reducing the time and space complexity. It thus establishes the ability of Genetic Algorithms for finding optimal solutions from a huge set of solutions. The work has been implemented and analyzed with satisfactory results.},
author = {Aiman, Umme and Asrar, Nausheen},
doi = {10.12691/JCSA-3-2-3},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aiman, Asrar - 2015 - Cite This Article Umme Aiman, and Nausheen Asrar.pdf:pdf},
journal = {Journal of Computer Sciences and Applications},
keywords = {10,12691,2,2015,3,33-39,and applications,and nausheen asrar,cite this article,doi,genetic algorithm,genetic algorithm based solution,intraceability,jcsa-3-2-3,journal of computer sciences,no,np complete problem,optimal solution,problem,sat-3 problem,to sat-3,umme aiman,vol},
number = {2},
pages = {33--39},
title = {{Genetic Algorithm Based Solution to SAT-3 Problem}},
url = {http://pubs.sciepub.com/jcsa/3/2/3/},
volume = {3},
year = {2015}
}
@article{Immerman1990,
author = {Immerman, N},
doi = {10.1146/annurev.cs.04.060190.000541},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/ALRch27.pdf:pdf},
issn = {8756-7016},
journal = {Annual Review of Computer Science},
number = {1},
pages = {105--117},
title = {{Complexity Classes}},
volume = {4},
year = {1990}
}
@incollection{Jyotishree,
abstract = {Selection is the first genetic operation in the reproductive phase of genetic algorithm. The objective of selection is to choose the fitter individuals in the population that will create offsprings for the next generation, commonly known as mating pool. The mating pool thus selected takes part in further genetic operations, advancing the population to the next generation and hopefully close to the optimal solution. In other words, Selection is the process of choosing breeding stock or parents from a population. As the generations pass, the members of population should get fitter and fitter. Individuals from the mating pool are used to generate new offsprings, with the resulting offspring forming the basis of next generation. So it is desirable that the mating pool should have good individuals. Selection operator works at the level of chromosomes. The key idea of selection operator is to give preference to better individuals by allowing them to pass on their genes to the next generation and prohibit the entrance of worst fit individuals into the next generation. The goodness of each individual depends on its fitness. Fitness value is determined by an objective function. Selection of individuals in the population is fitness dependent and is done using different algorithms [Goldberg et al. 1991]. Some are roulette wheel selection, rank selection, steady state selection and many more. Selection acts as driving force in a genetic algorithm by directing the genetic search towards promising regions in the search space. Selection operator emulates phenomena and processes in nature. Selection chooses more fit individuals in analogy to Darwin's theory of evolution-survival of fittest [Fogel 1995]. All the individuals have a chance of being selected into the mating pool, but there are chances that an individual in the population can be selected more than once depending upon its fitness. Selection schemes are characterised by selection pressure, selection variance and loss of diversity. They primarily determine the convergence characteristics of genetic algorithms. Selection has to be balanced. Too strong selection means suboptimal highly fit individuals will take over the population reducing the diversity and too weak selection will result in too slow evolution [Mitchell 1996].},
address = {Kurukshetra},
author = {Jyotishree, Jyotishree and Kumar, Rakesh},
booktitle = {Knowledge based operation and problems representation in genetic algorithms},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/16{\_}chapter 6.pdf:pdf},
organization = {Kurukshetra University},
pages = {94--124},
title = {{Chapter 6: SELECTION 6.1 Introduction}},
url = {http://shodhganga.inflibnet.ac.in/bitstream/10603/32680/16/16{\_}chapter 6.pdf},
year = {2012}
}
@article{Bacchus1995,
abstract = {We investigate the dynamic variable ordering (DVO) technique commonly used in conjunction with tree-search algorithms for solving constraint satisfaction problems. We first provide an implementation methodology for adding DVO to an arbitrary tree-search algorithm. Our methodology is applicable to a wide range of algorithms including those that maintain complicated information about the search history, like backmarking. We then investigate the popular reordering heuristic of next instantiating the variable with the minimum remaining values (MRV). We prove some interesting theorems about the MRV heuristic which demonstrate that if one wants to use the MRV heuristic one should use it with forward checking. Finally, we investigate the empirical performance of 12 different algorithms with and without DVO. Our experiments and theoretical results demonstrate that forward checking equipped with dynamic variable ordering is a very good algorithm for solving CSPs.},
author = {Bacchus, Fahiem and {Van Run}, Paul},
doi = {10.1007/3-540-60299-2_16},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/BvRCP95.pdf:pdf},
isbn = {3540602992},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {258--275},
title = {{Dynamic variable ordering in CSPs}},
volume = {976},
year = {1995}
}
@article{Biere2017,
author = {Biere, Armin},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/Biere-SAT-Competition-2017-solvers.pdf:pdf},
journal = {Proceedings of SAT Competition 2017 - Solver and Benchmark Descriptions},
pages = {14--15},
title = {{CaDiCaL, Lingeling, Plingeling, Treengeling, YalSAT Entering the SAT Competition 2017}},
url = {http://fmv.jku.at/papers/Biere-SAT-Competition-2017-solvers.pdf},
year = {2017}
}
@techreport{Khaji,
abstract = {Initial population plays an important role in heuristic algorithms such as GA as it help to decrease the time those algorithms need to achieve an acceptable result. Furthermore, it may influence the quality of the final answer given by evolutionary algorithms. In this paper, we shall introduce a heuristic method to generate a target based initial population which possess two mentioned characteristics. The efficiency of the proposed method has been shown by presenting the results of our tests on the benchmarks.},
archivePrefix = {arXiv},
arxivId = {1406.4518},
author = {Khaji, Erfan and Mohammadi, Amin Satlikh},
eprint = {1406.4518},
file = {:home/juan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khaji, Mohammadi, Students - Unknown - A Heuristic Method to Generate Better Initial Population for Evolutionary Methods.pdf:pdf},
title = {{A Heuristic Method to Generate Better Initial Population for Evolutionary Methods}},
url = {http://arxiv.org/abs/1406.4518},
year = {2014}
}
@misc{Karp2010,
abstract = {Throughout the 1960s I worked on combinatorial optimization problems including logic circuit design with Paul Roth and assembly line balancing and the traveling salesman problem with Mike Held. These experiences made me aware that seemingly simple discrete optimization problems could hold the seeds of combinatorial explosions. The work of Dantzig, Fulkerson, Hoffman, Edmonds, Lawler and other pioneers on network flows, matching and matroids acquainted me with the elegant and efficient algorithms that were sometimes possible. Jack Edmonds' papers and a few key discussions with him drew my attention to the crucial distinction between polynomial-time and superpolynomial-time solvability. I was also influenced by Jack's emphasis on min-max theorems as a tool for fast verification of optimal solutions, which foreshadowed Steve Cook's definition of the complexity class NP. Another influence was George Dantzig's suggestion that integer programming could serve as a universal format for combinatorial optimization problems. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
author = {Karp, Richard M.},
booktitle = {50 Years of Integer Programming 1958-2008: From the Early Years to the State-of-the-Art},
doi = {10.1007/978-3-540-68279-0_8},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/karp.pdf:pdf},
isbn = {9783540682745},
pages = {219--241},
title = {{Reducibility among combinatorial problems}},
year = {2010}
}
@article{Een2000,
author = {E{\'{e}}n, Niklas and Niklas, Sorensson},
file = {:home/juan/Gen{\_}Algorithm{\_}TFG/recursos{\_}tfg/papers/MiniSat.pdf:pdf},
title = {{Extensible SAT Solver}},
year = {2000}
}
